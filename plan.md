# ğŸ§  Job Dorker - Node.js Job Scraper using Google Dorks

## ğŸ“˜ Project Overview

**Goal:**  
Build a Node.js app that:

- Uses **Google Dorks** to search for job listings across multiple job boards
- Scrapes job data from search result links with intelligent parsing
- Generates comprehensive reports (CSV, PDF, JSON) with analytics
- Provides both CLI and optional Web UI interfaces
- Implements rate limiting and respectful scraping practices
- Supports job filtering, deduplication, and saved searches

---

## ğŸ§± Recommended Tech Stack

### ğŸ—ï¸ Core Runtime

- **Node.js** (v20 LTS) â€“ Latest stable with performance improvements
- **TypeScript** â€“ Type safety, better IDE support, fewer runtime errors

### ğŸŒ HTTP & Web Scraping

- **Got** (over Axios) â€“ Better performance, HTTP/2 support, built-in retry logic
- **Playwright** (primary) â€“ Modern, reliable, handles SPA sites, mobile testing
- **Cheerio** (secondary) â€“ Fast server-side DOM manipulation for static content
- **tough-cookie** â€“ Advanced cookie handling
- **user-agents** â€“ Realistic user agent rotation

### ğŸ“Š Data Processing & Storage

- **better-sqlite3** â€“ Faster than sqlite3, synchronous API, WAL mode
- **csv-stringify** (over csv-writer) â€“ Better streaming support
- **pdfkit** â€“ PDF generation (keep)
- **fast-json-stringify** â€“ 2-5x faster JSON serialization
- **lodash** â€“ Utility functions for data manipulation

### ğŸ¯ CLI & Interface

- **Commander.js** (over Inquirer) â€“ More flexible CLI argument parsing
- **ora** â€“ Beautiful terminal spinners
- **chalk** â€“ Terminal styling
- **boxen** â€“ Create boxes in terminal
- **table** â€“ ASCII table formatting

### ğŸ”§ Development & Quality

- **Vitest** (over Jest) â€“ Faster, better TypeScript support, ESM native
- **Biome** (over ESLint + Prettier) â€“ All-in-one linter/formatter, 100x faster
- **Husky** â€“ Git hooks (keep)
- **tsx** (over nodemon) â€“ Fast TypeScript execution
- **concurrently** â€“ Run multiple commands

### ğŸ“‹ Queue & Background Processing

- **Bullmq** (over Bull) â€“ Modern Redis-based queue, better TypeScript support
- **p-queue** â€“ Simple in-memory queue for rate limiting
- **bottleneck** â€“ Advanced rate limiting with clustering

### ğŸƒâ€â™‚ï¸ Performance & Monitoring

- **pino** (over Winston) â€“ 5x faster JSON logging
- **clinic.js** â€“ Performance profiling
- **autocannon** â€“ Load testing
- **0x** â€“ Flame graph profiling

### ğŸ›¡ï¸ Security & Validation

- **zod** â€“ Runtime type validation and parsing
- **helmet** â€“ Security headers (if web UI)
- **rate-limiter-flexible** â€“ Advanced rate limiting
- **validator** â€“ String validation utilities

### ğŸ”„ Optional Web Features

- **Fastify** (over Express) â€“ 2x faster, better TypeScript support
- **@fastify/static** â€“ Static file serving
- **@fastify/view** â€“ Template rendering
- **socket.io** â€“ Real-time updates for web UI

### ğŸ“¦ Build & Distribution

- **tsup** â€“ Fast TypeScript bundler
- **pkg** â€“ Create executable binaries
- **Docker** â€“ Containerization
- **semantic-release** â€“ Automated versioning

---

## ğŸ¯ Tech Stack Rationale

### Why These Choices?

#### **Playwright over Puppeteer**

- âœ… **Cross-browser support** (Chrome, Firefox, Safari)
- âœ… **Better handling of modern SPAs** (React, Vue job sites)
- âœ… **Mobile device emulation** for responsive scraping
- âœ… **Auto-wait functionality** reduces flaky tests
- âœ… **Network interception** for advanced debugging

#### **TypeScript over JavaScript**

- âœ… **Catch errors at compile time** vs runtime
- âœ… **Better IDE support** with autocomplete
- âœ… **Self-documenting code** with interfaces
- âœ… **Easier refactoring** as project grows
- âœ… **Better team collaboration**

#### **Got over Axios**

- âœ… **HTTP/2 support** for better performance
- âœ… **Built-in retry logic** with exponential backoff
- âœ… **Advanced caching** capabilities
- âœ… **Better error handling** with detailed context
- âœ… **Smaller bundle size**

#### **Vitest over Jest**

- âœ… **Native ESM support** without configuration
- âœ… **Better TypeScript integration**
- âœ… **Faster test execution** (uses Vite's transform pipeline)
- âœ… **Modern snapshot testing**
- âœ… **Better watch mode**

#### **BullMQ over Bull**

- âœ… **Modern TypeScript support**
- âœ… **Better Redis Cluster support**
- âœ… **Advanced job patterns** (batches, flows)
- âœ… **Built-in rate limiting**
- âœ… **Better observability**

#### **Pino over Winston**

- âœ… **5x faster performance**
- âœ… **JSON-first logging** for structured logs
- âœ… **Better memory usage**
- âœ… **Child logger support**
- âœ… **Excellent ecosystem**

#### **Better-SQLite3 over SQLite3**

- âœ… **Synchronous API** simplifies code
- âœ… **WAL mode** for better concurrent access
- âœ… **Better performance** with prepared statements
- âœ… **TypeScript-friendly**

### ğŸ“‹ Alternative Considerations

#### **For Enterprise Scale:**

- **PostgreSQL** instead of SQLite for multi-user scenarios
- **Redis** for distributed caching and sessions
- **RabbitMQ** for enterprise messaging patterns
- **Prometheus + Grafana** for metrics and monitoring

#### **For Cloud Deployment:**

- **Serverless options:** AWS Lambda, Vercel Functions
- **Container orchestration:** Kubernetes, Docker Swarm
- **Cloud databases:** PlanetScale, Supabase, MongoDB Atlas
- **Message queues:** AWS SQS, Google Cloud Tasks

---

## ğŸ—ï¸ Updated Project Structure

```text
job-dorker/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ types/                    # TypeScript type definitions
â”‚   â”‚   â”œâ”€â”€ job.types.ts
â”‚   â”‚   â”œâ”€â”€ scraper.types.ts
â”‚   â”‚   â””â”€â”€ config.types.ts
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ base-scraper.ts       # Abstract base class
â”‚   â”‚   â”œâ”€â”€ playwright-scraper.ts # Dynamic content scraper
â”‚   â”‚   â”œâ”€â”€ cheerio-scraper.ts    # Static content scraper
â”‚   â”‚   â””â”€â”€ sites/                # Site-specific implementations
â”‚   â”‚       â”œâ”€â”€ linkedin.scraper.ts
â”‚   â”‚       â”œâ”€â”€ indeed.scraper.ts
â”‚   â”‚       â””â”€â”€ glassdoor.scraper.ts
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ job-parser.ts
â”‚   â”‚   â”œâ”€â”€ schemas/              # Zod validation schemas
â”‚   â”‚   â””â”€â”€ extractors/           # Site-specific extractors
â”‚   â”œâ”€â”€ generators/
â”‚   â”‚   â”œâ”€â”€ base-generator.ts
â”‚   â”‚   â”œâ”€â”€ csv.generator.ts
â”‚   â”‚   â”œâ”€â”€ pdf.generator.ts
â”‚   â”‚   â””â”€â”€ json.generator.ts
â”‚   â”œâ”€â”€ queue/
â”‚   â”‚   â”œâ”€â”€ job-queue.ts          # BullMQ setup
â”‚   â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â””â”€â”€ schedulers/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ rate-limiter.ts
â”‚   â”‚   â”œâ”€â”€ logger.ts             # Pino configuration
â”‚   â”‚   â”œâ”€â”€ deduplicator.ts
â”‚   â”‚   â”œâ”€â”€ validators.ts         # Zod schemas
â”‚   â”‚   â””â”€â”€ cache.ts              # Caching utilities
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ connection.ts         # Better-SQLite3 setup
â”‚   â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â”œâ”€â”€ index.ts              # Commander.js setup
â”‚   â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â””â”€â”€ prompts/
â”‚   â”œâ”€â”€ web/                      # Optional Fastify web UI
â”‚   â”‚   â”œâ”€â”€ server.ts
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ plugins/
â”‚   â”‚   â””â”€â”€ static/
â”‚   â””â”€â”€ index.ts
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ e2e/                      # Playwright E2E tests
â”‚   â”œâ”€â”€ fixtures/
â”‚   â””â”€â”€ helpers/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build.ts
â”‚   â”œâ”€â”€ migrate.ts
â”‚   â””â”€â”€ seed.ts
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ vitest.config.ts
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ biome.json
â”‚   â””â”€â”€ playwright.config.ts
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ docker-compose.dev.yml
â””â”€â”€ dist/                         # Built TypeScript output
```

---

## ğŸ—ï¸ Project Structure

```text
job-dorker/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ base-scraper.js
â”‚   â”‚   â”œâ”€â”€ google-dork-scraper.js
â”‚   â”‚   â”œâ”€â”€ linkedin-scraper.js
â”‚   â”‚   â””â”€â”€ indeed-scraper.js
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ job-parser.js
â”‚   â”‚   â””â”€â”€ site-specific-parsers/
â”‚   â”œâ”€â”€ generators/
â”‚   â”‚   â”œâ”€â”€ csv-generator.js
â”‚   â”‚   â”œâ”€â”€ pdf-generator.js
â”‚   â”‚   â””â”€â”€ json-generator.js
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ rate-limiter.js
â”‚   â”‚   â”œâ”€â”€ logger.js
â”‚   â”‚   â”œâ”€â”€ deduplicator.js
â”‚   â”‚   â””â”€â”€ validators.js
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ dorks.js
â”‚   â”‚   â””â”€â”€ settings.js
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â””â”€â”€ index.js
â”‚   â”œâ”€â”€ web/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â””â”€â”€ public/
â”‚   â””â”€â”€ index.js
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ fixtures/
â”œâ”€â”€ docs/
â”œâ”€â”€ scripts/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ jest.config.js
â”œâ”€â”€ package.json
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .eslintrc.js
â”œâ”€â”€ .prettierrc
â””â”€â”€ docker-compose.yml
```

---

## ğŸ” Google Dorks Strategy

### Target Job Sites

- LinkedIn Jobs
- Indeed
- Glassdoor
- AngelList/Wellfound
- RemoteOK
- Stack Overflow Jobs
- Company career pages

### Example Dorks

```text

site:linkedin.com/jobs "software engineer" location:remote
site:indeed.com "node.js developer" -intern
site:glassdoor.com "full stack" salary:>80000
filetype:pdf "job description" "react developer"
```

---

## ğŸ§ª Testing Strategy

### Unit Tests

- Scraper functions
- Data parsers
- Report generators
- Utility functions
- Configuration validation

### Integration Tests

- End-to-end scraping workflows
- Report generation pipeline
- CLI interface testing
- Web API endpoints

### Test Coverage Goals

- **Minimum:** 80% code coverage
- **Target:** 90% code coverage

### Testing Tools

```bash

npm test              # Run all tests
npm run test:unit     # Unit tests only
npm run test:integration # Integration tests
npm run test:coverage # Coverage report
npm run test:watch    # Watch mode
```

---

## ğŸš€ CI/CD Pipeline

### GitHub Actions Workflow

#### On Push/PR:

1. **Lint & Format Check**
   - ESLint validation
   - Prettier format check
   - Package vulnerability audit

2. **Test Suite**
   - Unit tests (Node.js 16, 18, 20)
   - Integration tests
   - Coverage reporting to Codecov

3. **Security Checks**
   - npm audit
   - CodeQL analysis
   - Dependency vulnerability scan

#### On Release

1. **Build & Package**
   - Create distribution bundle
   - Generate documentation
   - Docker image build

2. **Deploy**
   - Publish to npm (if library)
   - Deploy to staging environment
   - Create GitHub release

### Environments

- **Development:** Local development
- **Staging:** Pre-production testing
- **Production:** Live deployment (if web version)

---

## ğŸ“‹ Current Status & Progress

### âœ… Phase 1: Core Foundation (COMPLETE)
- âœ… Initialize Node.js project with proper package.json
- âœ… Set up development environment (ESLint, Prettier, Husky) 
- âœ… Implement basic project structure
- âœ… Create base scraper class with rate limiting
- âœ… Implement Google Dorks generator
- âœ… Build job data parser system
- âœ… Add comprehensive logging system (Winston)
- âœ… Write initial unit tests (67 tests passing)

### âœ… Phase 2: Scraping Engine (COMPLETE)
- âœ… Implement Cheerio-based scraper for static content
- âœ… Add Playwright support for dynamic content (LinkedIn, Glassdoor)
- âœ… Create site-specific parsers with intelligent detection
- âœ… Implement job deduplication logic
- âœ… Add error handling and retry mechanisms
- âœ… Build data validation system
- âœ… Add progress indicators and spinners
- âœ… Implement concurrent scraping with queue management

### âœ… Phase 3: Database Layer (COMPLETE)

- âœ… SQLite database integration with better-sqlite3
- âœ… Database connection management with WAL mode
- âœ… Migration system with smart SQL parsing
- âœ… Job repository with CRUD operations
- âœ… Full-text search capabilities
- âœ… Database backup and statistics
- âœ… Report generation system

### âœ… Phase 4: Web Interface (COMPLETE)

- âœ… Fastify web server setup
- âœ… RESTful API endpoints for jobs
- âœ… Modern responsive web interface
- âœ… Real-time job search and filtering
- âœ… Interactive job analytics dashboard
- âœ… Web-based report generation
- âœ… Mobile-friendly responsive design

### âœ… Phase 5: Docker Deployment (COMPLETE)

- âœ… Docker multi-stage builds with Node.js 20.15 compatibility
- âœ… Production container with SQLite database setup
- âœ… Development container with hot reload support
- âœ… Docker Compose orchestration with Redis integration
- âœ… Health checks for all services
- âœ… Working web interface containerization

### ğŸ“ Phase 6: Report Generation (NEXT)

- â³ Enhanced CSV export with customizable columns
- â³ Advanced JSON export with analytics
- â³ PDF report with charts and visualization
- â³ Report templates and branding
- â³ Automated report scheduling
- â³ Data filtering and summary statistics

---

## ğŸ“‹ TODO List

### âœ… Phase 1: Core Foundation (Week 1-2) - COMPLETE

- [x] Initialize Node.js project with proper package.json
- [x] Set up development environment (ESLint, Prettier, Husky)
- [x] Implement basic project structure
- [x] Create base scraper class with rate limiting
- [x] Implement Google Dorks generator
- [x] Build simple job data parser
- [x] Add basic logging system
- [x] Write initial unit tests

### âœ… Phase 2: Scraping Engine (Week 3-4) - COMPLETE

- [x] Implement Cheerio-based scraper for static content
- [x] Add Playwright support for dynamic content
- [x] Create site-specific parsers (LinkedIn, Indeed, etc.)
- [x] Implement job deduplication logic
- [x] Add error handling and retry mechanisms
- [x] Build data validation system
- [x] Add progress indicators
- [x] Implement concurrent scraping with queue

### âœ… Phase 3: Database & Storage (Week 5) - COMPLETE

- [x] SQLite database integration with better-sqlite3
- [x] Database connection management with WAL mode
- [x] Migration system with smart SQL parsing
- [x] Job repository with CRUD operations
- [x] Full-text search capabilities
- [x] Database backup and statistics

### âœ… Phase 4: Web Interface (Week 6) - COMPLETE

- [x] Fastify web server setup
- [x] RESTful API endpoints for jobs
- [x] Modern responsive web interface
- [x] Real-time job search and filtering
- [x] Interactive job analytics dashboard
- [x] Web-based report generation

### âœ… Phase 5: Docker Deployment (Week 7) - COMPLETE

- [x] Docker containerization with multi-stage builds
- [x] Docker Compose orchestration
- [x] Health checks and monitoring
- [x] Production and development environments
- [x] Redis integration for queue management

### ğŸ“ Phase 6: Enhanced Reports & CLI (Week 8) - NEXT

- [ ] Enhanced CSV export with customizable columns
- [ ] Advanced PDF reports with charts and analytics
- [ ] JSON export with structured analytics data
- [ ] Interactive CLI with Inquirer
- [ ] Command-line arguments parsing
- [ ] Report templates and scheduling
- [ ] Data filtering and summary statistics

### Phase 7: Testing & Quality (Week 9)

- [ ] Comprehensive unit test suite expansion
- [ ] Integration tests for all workflows
- [ ] Performance benchmarking
- [ ] Security testing and audit
- [ ] Documentation completion
- [ ] Load testing and optimization

### Phase 6: Advanced Features (Week 8+)

- [ ] Web UI with Express
- [ ] Job alerts and notifications
- [ ] Database integration for job storage
- [ ] API endpoints for external integration
- [ ] Scheduled scraping with cron
- [ ] Job matching algorithms
- [ ] Company research integration

### Phase 7: Deployment & Monitoring (Ongoing)

- [ ] Docker containerization
- [ ] CI/CD pipeline setup
- [ ] Monitoring and alerting
- [ ] Performance optimization
- [ ] Documentation website
- [ ] Community features

### ğŸš€ Future Enhancement Plans

#### Career Management Suite

- [ ] **CV Upload & Management**
  - PDF/DOCX resume parsing and analysis
  - Skills extraction and gap analysis
  - Resume optimization recommendations
  - Multiple CV version management

- [ ] **Education Hub**
  - Course recommendations based on job requirements
  - Certification tracking and expiration alerts
  - Learning path suggestions
  - Integration with online learning platforms

- [ ] **Google Drive Integration**
  - Read-only access to shared certification folders
  - Automatic certificate parsing and validation
  - Portfolio document management
  - Shared reference document access

- [ ] **AI-Powered Features**
  - Job description analysis and matching
  - Resume-to-job compatibility scoring
  - Interview preparation question generation
  - Career progression recommendations
  - Salary negotiation insights

- [ ] **Advanced Analytics**
  - Job market trend analysis
  - Company culture insights
  - Skills demand forecasting
  - Geographic job market analysis

#### Integration & Automation

- [ ] **Third-Party Integrations**
  - LinkedIn profile sync
  - GitHub portfolio integration
  - Calendar scheduling for applications
  - CRM-style application tracking

- [ ] **Smart Notifications**
  - AI-curated job recommendations
  - Application deadline reminders
  - Market trend alerts
  - Skills development suggestions

---

## ğŸ”’ Security & Ethics

### Respectful Scraping

- Implement proper rate limiting (1-2 requests/second)
- Respect robots.txt files
- Add random delays between requests
- Use rotating user agents
- Implement circuit breakers for failed requests

### Data Privacy

- No personal data collection beyond public job listings
- Secure handling of any cached data
- Option to anonymize company information
- Clear data retention policies

### Legal Considerations

- Terms of service compliance
- Fair use guidelines
- Attribution where required
- Rate limiting to avoid service disruption

---

## ğŸ“Š Monitoring & Analytics

### Metrics to Track

- Scraping success rates by site
- Job discovery statistics
- Processing time performance
- Error rates and types
- User engagement (CLI/Web)

### Logging Strategy

- Structured logging with Winston
- Log levels: ERROR, WARN, INFO, DEBUG
- Rotation and retention policies
- Performance monitoring

---

## ğŸ”§ Configuration Management

### Environment Variables

```bash
# .env
NODE_ENV=development
LOG_LEVEL=info
SCRAPE_DELAY=2000
MAX_CONCURRENT_REQUESTS=5
OUTPUT_DIRECTORY=./reports
DATABASE_URL=sqlite:./jobs.db
WEB_PORT=3000
```

### Configuration Files

- `config/dorks.json` - Google Dork patterns
- `config/sites.json` - Supported job sites
- `config/parsers.json` - Parser configurations

---

## ğŸ“ˆ Performance Optimization

### Caching Strategy

- Cache job listings to avoid duplicate processing
- Cache parsed site structures
- Implement intelligent cache invalidation

### Scalability Considerations

- Queue-based processing for large scraping jobs
- Database indexing for fast job searches
- Pagination for large result sets
- Memory management for long-running processes

---

## ğŸ“š Documentation Plan

- [ ] API documentation with JSDoc
- [ ] User guide for CLI usage
- [ ] Developer setup instructions
- [ ] Scraping best practices guide
- [ ] Troubleshooting guide
- [ ] Contributing guidelines

---

## ğŸ¯ Success Metrics

### Technical KPIs

- 95%+ uptime for scraping operations
- <5 second average response time
- 80%+ successful job extraction rate
- Zero security vulnerabilities

### User Experience KPIs

- Intuitive CLI interface
- Clear error messages
- Comprehensive reporting
- Fast report generation (<30 seconds for 100 jobs)
